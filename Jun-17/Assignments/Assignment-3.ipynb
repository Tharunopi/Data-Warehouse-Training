{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64dd0c2d-1b30-4ede-a045-2f2681285cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Assignment-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dae7e24-31f9-49ed-a5a9-ef2c154ca16d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window as W\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64595ea0-b0bd-4e8a-a9c7-4bc5d21bec11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"dbshell-01\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ce08d5d-2ba7-412e-a781-5471c905293a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Basics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ce20f4-8b02-484c-be1f-6229aa5311a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- EmployeeID: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Project: string (nullable = true)\n |-- WorkHours: integer (nullable = true)\n |-- WorkDate: date (nullable = true)\n |-- Location: string (nullable = true)\n |-- Mode: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the CSV using inferred schema.\n",
    "dfEmp = spark.read.csv(\"/FileStore/tables/employee_timesheet.csv\", header=True, inferSchema=True)\n",
    "dfEmp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c09c2c4-0694-4a30-a7bf-b929410c347f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- EmployeeID: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Project: string (nullable = true)\n |-- WorkHours: integer (nullable = true)\n |-- WorkDate: date (nullable = true)\n |-- Location: string (nullable = true)\n |-- Mode: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Load the same file with schema explicitly defined.\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"EmployeeID\", StringType()),\n",
    "        StructField(\"Name\", StringType()),\n",
    "        StructField(\"Department\", StringType()),\n",
    "        StructField(\"Project\", StringType()),\n",
    "        StructField(\"WorkHours\", IntegerType()),\n",
    "        StructField(\"WorkDate\", DateType()),\n",
    "        StructField(\"Location\", StringType()),\n",
    "        StructField(\"Mode\", StringType())\n",
    "    ]\n",
    ")\n",
    "dfExpSchema = spark.read.csv(\"/FileStore/tables/employee_timesheet.csv\", header=True, schema=schema)\n",
    "dfExpSchema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd2dd483-fbb3-44ef-b501-1d9d3082e2b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+-------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|WeekDay|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|      4|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|      4|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|      5|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|      6|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|      6|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|      7|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Add a new column Weekday extracted from WorkDate .\n",
    "dfEmp = dfEmp.withColumn(\"WeekDay\", F.dayofweek(F.col(\"WorkDate\")))\n",
    "dfEmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f5fd37e-e666-43d9-a9db-2d3411745ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Aggregations & Grouping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff33bc7b-12ce-4662-931e-0cacc05613f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n|EmployeeID| Name|TotalHours|\n+----------+-----+----------+\n|      E103| John|         5|\n|      E104|Meena|         6|\n|      E102|  Raj|        15|\n|      E101|Anita|        17|\n+----------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Calculate total work hours by employee.\n",
    "dfEmp.groupBy([\"EmployeeID\", \"Name\"]).agg(\n",
    "  F.sum(\"WorkHours\").alias(\"TotalHours\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4c14754-92c0-4292-a0dc-91f87bf09443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n|Department|AverageWorkHour|\n+----------+---------------+\n|        HR|            7.5|\n|   Finance|            5.0|\n|        IT|           7.67|\n+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Calculate average work hours per department.\n",
    "dfEmp.groupBy(\"Department\").agg(\n",
    "    F.round(F.mean(\"WorkHours\"), 2).alias(\"AverageWorkHour\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56cc46dc-b8ce-44b1-b144-805a35b7cda8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+----+\n|EmployeeID| Name|TotalHours|Rank|\n+----------+-----+----------+----+\n|      E101|Anita|        17|   1|\n|      E102|  Raj|        15|   2|\n+----------+-----+----------+----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Get top 2 employees by total hours using window function.\n",
    "win = W.orderBy(F.desc(\"TotalHours\"))\n",
    "dfEmp.groupBy([\"EmployeeID\", \"Name\"]) \\\n",
    "    .agg(F.sum(\"WorkHours\").alias(\"TotalHours\")) \\\n",
    "    .withColumn(\"Rank\", F.rank().over(win)) \\\n",
    "    .sort(\"Rank\") \\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3b63a1d-11ca-4491-92c9-1f47c48673f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Date Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eadfd56b-7f37-4b9b-962a-fe060a218fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+-------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|WeekDay|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|      6|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|      6|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|      7|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Filter entries where WorkDate falls on a weekend.\n",
    "dfEmp.filter((dfEmp.WeekDay == 6) | (dfEmp.WeekDay == 7)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc30dd29-e7b7-4523-a24f-af84fb9f2f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+-------+------------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|WeekDay|RunningTotal|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+------------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|      4|           8|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|      6|          17|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|      4|           7|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|      7|          15|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|      5|           5|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|      6|           6|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8. Calculate running total of hours per employee using window.\n",
    "win3 = W.partitionBy(\"EmployeeID\").orderBy(\"WorkDate\")\n",
    "\n",
    "dfEmp.withColumn(\"RunningTotal\", F.sum(\"WorkHours\").over(win3)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49eccd80-a83e-4907-b45a-2b0c748a330a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Joining DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c52f9cf-a212-4679-b295-0e9ea799daa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n|Department|DeptHead|\n+----------+--------+\n|        IT|   Anand|\n|        HR| Shruthi|\n|   Finance|   Kamal|\n+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"IT\", \"Anand\"), (\"HR\", \"Shruthi\"), (\"Finance\", \"Kamal\")]\n",
    "columns = [\"Department\", \"DeptHead\"]\n",
    "department_location = spark.createDataFrame(data, columns)\n",
    "department_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac1a0aa6-47ba-42d7-8048-716299969506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------+\n| Name|Department|DeptHead|\n+-----+----------+--------+\n|Meena|        IT|   Anand|\n|Anita|        IT|   Anand|\n|Anita|        IT|   Anand|\n|  Raj|        HR| Shruthi|\n|  Raj|        HR| Shruthi|\n| John|   Finance|   Kamal|\n+-----+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Join with timesheet data and list all employees with their DeptHead.\n",
    "dfJoined = dfEmp.join(department_location, on=\"Department\", how=\"inner\")\n",
    "dfJoined.select([\"Name\", \"Department\", \"DeptHead\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b3f313a-757a-492d-af2d-ecab9b0b374a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Pivot & Unpivot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40c14ad-f633-424c-b28c-ff105e8f121d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+-----+\n| Name|Alpha|Beta|Gamma|\n+-----+-----+----+-----+\n| John|    5|   0|    0|\n|Anita|   17|   0|    0|\n|  Raj|    0|  15|    0|\n|Meena|    0|   0|    6|\n+-----+-----+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 11. Pivot table: total hours per employee per project.\n",
    "dfPivot = dfEmp.groupBy(\"Name\") \\\n",
    "  .pivot(\"Project\") \\\n",
    "  .agg(F.sum(\"WorkHours\")) \\\n",
    "  .fillna(0)\n",
    "\n",
    "dfPivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "671ba4b1-aa36-4bdb-afc0-a4ea88e887ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----------+\n| Name|Project|TotalHours|\n+-----+-------+----------+\n| John|  Alpha|         5|\n| John|   Beta|         0|\n| John|  Gamma|         0|\n|Anita|  Alpha|        17|\n|Anita|   Beta|         0|\n|Anita|  Gamma|         0|\n|  Raj|  Alpha|         0|\n|  Raj|   Beta|        15|\n|  Raj|  Gamma|         0|\n|Meena|  Alpha|         0|\n|Meena|   Beta|         0|\n|Meena|  Gamma|         6|\n+-----+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 12. Unpivot example: Convert mode-specific hours into rows.\n",
    "dfPivot.unpivot(\"Name\", [\"Alpha\", \"Beta\", \"Gamma\"], \"Project\", \"TotalHours\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a160dafa-41a0-4c00-b265-1efed57e865f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **UDF & Conditional Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c06829d-d750-43c3-8ab0-508d684b777c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 13. Create a UDF to classify work hours:\n",
    "def workloadTag(hours):\n",
    "  if hours >= 8:\n",
    "    return \"Full\"\n",
    "  if hours >=4:\n",
    "    return \"Partial\"\n",
    "  return \"Light\"\n",
    "\n",
    "tagger = F.udf(workloadTag, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d24e7363-0884-43a9-98f3-0d03f678cecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+-------+----------------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|WeekDay|WorkLoadCategory|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+----------------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|      4|            Full|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|      4|         Partial|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|      5|         Partial|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|      6|            Full|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|      6|         Partial|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|      7|            Full|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 14. Add a column WorkloadCategory using this UDF.\n",
    "dfEmp.withColumn(\"WorkLoadCategory\", tagger(F.col(\"WorkHours\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "429611a6-c8c3-44fa-98d0-3dae9783d78b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Nulls and Cleanup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0847d4b-93ee-44de-a9e5-4bb67d94eb5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+-------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|WeekDay|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|      4|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|  null|      4|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|      5|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|      6|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|  null|      6|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|      7|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 15. Introduce some nulls in Mode column.\n",
    "dfNulls = dfEmp.withColumn(\"Mode\", F.when(dfEmp.Mode == \"Onsite\", None).otherwise(dfEmp.Mode))\n",
    "dfNulls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da5d2cd7-e905-4b77-9557-5091fee7eed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------------+-------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|        Mode|WeekDay|\n+----------+-----+----------+-------+---------+----------+---------+------------+-------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|      Remote|      4|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Not Provided|      4|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|      Remote|      5|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|      Remote|      6|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Not Provided|      6|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|      Remote|      7|\n+----------+-----+----------+-------+---------+----------+---------+------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 16. Fill nulls with \"Not Provided\".\n",
    "dfNulls = dfNulls.fillna(\"Not Provided\", subset=\"Mode\")\n",
    "dfNulls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9ae0684-292c-45cc-b6c2-8e222c3f084f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------------+-------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|        Mode|WeekDay|\n+----------+-----+----------+-------+---------+----------+---------+------------+-------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|      Remote|      4|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Not Provided|      4|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|      Remote|      5|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|      Remote|      6|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Not Provided|      6|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|      Remote|      7|\n+----------+-----+----------+-------+---------+----------+---------+------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# 17. Drop rows where WorkHours < 4.\n",
    "dfNew = dfNulls.filter(dfNulls.WorkHours >= 4)\n",
    "dfNew.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ed778e3-56a4-4406-9578-869e49272480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Advanced Conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2cbafc7-2c3d-4503-b3b0-16512e4bf49d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+---------+------------+\n|EmployeeID| Name|RemoteWork|TotalWork|  Percentage|\n+----------+-----+----------+---------+------------+\n|      E103| John|         1|        1|RemoteWorker|\n|      E104|Meena|         0|        1|   NotRemote|\n|      E102|  Raj|         1|        2|   NotRemote|\n|      E101|Anita|         2|        2|RemoteWorker|\n+----------+-----+----------+---------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 18. Use when-otherwise to mark employees as \"Remote Worker\" if >80% entries are Remote.\n",
    "dfEmp.groupBy([\"EmployeeID\", \"Name\"]) \\\n",
    "  .agg(\n",
    "  F.sum(F.when(F.col(\"Mode\") == \"Remote\", 1).otherwise(0)).alias(\"RemoteWork\"),\n",
    "  F.count(\"Mode\").alias(\"TotalWork\")\n",
    ") \\\n",
    ".withColumn(\"Percentage\", F.when((F.col(\"RemoteWork\") / F.col(\"TotalWork\")) > 0.80, \"RemoteWorker\").otherwise(\"NotRemote\"))  \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ba6fc2b-b0f6-4dfe-92c9-1a6cf73a57da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+-------+----------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|WeekDay|ExtraHours|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+----------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|      4|         0|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|      4|         0|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|      5|         0|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|      6|         1|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|      6|         0|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|      7|         0|\n+----------+-----+----------+-------+---------+----------+---------+------+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 19. Add a new column ExtraHours where hours > 8.\n",
    "dfEmp.withColumn(\"ExtraHours\", F.when(F.col(\"WorkHours\") > 8, F.col(\"WorkHours\") - 8).otherwise(0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af3824b7-005e-492b-a5aa-e804ceff10fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Union + Duplicate Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b000c25d-0c79-4208-9cda-3555cc5f2f81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|\n+----------+-----+----------+-------+---------+----------+---------+------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|\n|      E108|  Ram|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|\n|      E109| Eren|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|\n+----------+-----+----------+-------+---------+----------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 20. Append a dummy timesheet for new interns using unionByName() .\n",
    "interData = [\n",
    "  (\"E108\",\"Ram\",\"IT\",\"Alpha\",8,\"2024-05-01\",\"Bangalore\",\"Remote\"),\n",
    "  (\"E109\",\"Eren\",\"HR\",\"Beta\",7,\"2024-05-01\",\"Mumbai\",\"Onsite\")\n",
    "]\n",
    "columns = [\"EmployeeID\",\"Name\",\"Department\",\"Project\",\"WorkHours\",\"WorkDate\",\"Location\",\"Mode\"]\n",
    "\n",
    "dfInterns = spark.createDataFrame(interData, columns)\n",
    "\n",
    "dfInEmp = dfEmp.drop(\"WeekDay\").unionByName(dfInterns)\n",
    "dfInEmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10143431-f105-4b72-9344-eca67ab6cf1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|\n+----------+-----+----------+-------+---------+----------+---------+------+\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|\n|      E108|  Ram|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|\n|      E109| Eren|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|\n+----------+-----+----------+-------+---------+----------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 21. Remove duplicate rows based on all columns.\n",
    "dfInEmp.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0860849-d781-436c-83af-efa9199ede46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment-1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}