{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd8754a-b206-4339-b336-58f8e0e7a3c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7cbdad0-8066-4c4c-a01f-b8453b290b10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1520322650531891#setting/sparkui/0611-042249-grg1r6w4/driver-1255471792126635555\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x72d62252dd60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"NB-1\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "895f4e6e-179a-493c-8b88-232493b6d9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "313e92a1-826f-458c-b78b-e4cd20f4f093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "(\"Ananya\", \"HR\", 52000),\n",
    "(\"Rahul\", \"Engineering\", 65000),\n",
    "(\"Priya\", \"Engineering\", 60000),\n",
    "(\"Zoya\", \"Marketing\", 48000),\n",
    "(\"Karan\", \"HR\", 53000),\n",
    "(\"Naveen\", \"Engineering\", 70000),\n",
    "(\"Fatima\", \"Marketing\", 45000)\n",
    "]\n",
    "columns = [\"Name\", \"Department\", \"Salary\"]\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5aa553d-43a1-4e4e-88f1-01527a324952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "performance = [\n",
    "(\"Ananya\", 2023, 4.5),\n",
    "(\"Rahul\", 2023, 4.9),\n",
    "(\"Priya\", 2023, 4.3),\n",
    "(\"Zoya\", 2023, 3.8),\n",
    "(\"Karan\", 2023, 4.1),\n",
    "(\"Naveen\", 2023, 4.7),\n",
    "(\"Fatima\", 2023, 3.9)\n",
    "]\n",
    "columns_perf = [\"Name\", \"Year\", \"Rating\"]\n",
    "df_perf = spark.createDataFrame(performance, columns_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a92bc072-b8c8-4be8-a320-5be1f98c9543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Groupby and Aggregations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e90f4c33-177c-405c-9198-70690cfaf0e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n| Department|Average Salary|\n+-----------+--------------+\n|         HR|       52500.0|\n|Engineering|       65000.0|\n|  Marketing|       46500.0|\n+-----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Get the average salary by department.\n",
    "df.groupby(\"Department\").agg(\n",
    "    F.mean(\"Salary\").alias(\"Average Salary\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a0beed7-d1ed-486d-9e16-b43f9b50a421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n| Department|Employee count|\n+-----------+--------------+\n|         HR|             2|\n|Engineering|             3|\n|  Marketing|             2|\n+-----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Count of employees per department.\n",
    "df.groupby(\"Department\").agg(\n",
    "    F.count(\"Name\").alias(\"Employee count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4daaba0c-a095-43d0-9c8c-4e2af62d5878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n|Min Salary|Max Salary|\n+----------+----------+\n|     60000|     70000|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Maximum and minimum salary in Engineering.\n",
    "df.filter(df.Department == \"Engineering\").agg(\n",
    "    F.min(\"Salary\").alias(\"Min Salary\"),\n",
    "    F.max(\"Salary\").alias(\"Max Salary\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "389efe4a-9a43-4a57-b9bf-b37d55d9f478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Join and Combine Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20e85903-5fc0-4c24-9258-e4514040b641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----+------+\n|  Name| Department|Salary|Year|Rating|\n+------+-----------+------+----+------+\n|Ananya|         HR| 52000|2023|   4.5|\n| Rahul|Engineering| 65000|2023|   4.9|\n| Priya|Engineering| 60000|2023|   4.3|\n|  Zoya|  Marketing| 48000|2023|   3.8|\n| Karan|         HR| 53000|2023|   4.1|\n|Naveen|Engineering| 70000|2023|   4.7|\n|Fatima|  Marketing| 45000|2023|   3.9|\n+------+-----------+------+----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Perform an inner join between employee_data and performance_data on Name .\n",
    "df_joined = df.join(df_perf, on=\"Name\", how=\"inner\")\n",
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83b440b1-ea6b-4540-861b-7fd542288e5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n|  Name|Salary|Rating|\n+------+------+------+\n|Ananya| 52000|   4.5|\n| Rahul| 65000|   4.9|\n| Priya| 60000|   4.3|\n|  Zoya| 48000|   3.8|\n| Karan| 53000|   4.1|\n|Naveen| 70000|   4.7|\n|Fatima| 45000|   3.9|\n+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Show each employeeâ€™s salary and performance rating.\n",
    "df_joined.select([\"Name\", \"Salary\", \"Rating\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d4ac4d-812c-4774-ad7e-1e3eb3a75fb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n|  Name|Salary|Rating|\n+------+------+------+\n| Rahul| 65000|   4.9|\n|Naveen| 70000|   4.7|\n+------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Filter employees with rating > 4.5 and salary > 60000.\n",
    "df_joined.select([\"Name\", \"Salary\", \"Rating\"]).filter((df_joined.Salary > 60_000) & (df_joined.Rating > 4.5)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8902f86d-b36b-4507-9caa-6b90d1533200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Window & Rank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c20fbe-5c56-4542-9736-d9f5b766ee92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----+\n|  Name| Department|Salary|Rank|\n+------+-----------+------+----+\n|Naveen|Engineering| 70000|   1|\n| Rahul|Engineering| 65000|   2|\n| Priya|Engineering| 60000|   3|\n| Karan|         HR| 53000|   1|\n|Ananya|         HR| 52000|   2|\n|  Zoya|  Marketing| 48000|   1|\n|Fatima|  Marketing| 45000|   2|\n+------+-----------+------+----+\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Rank employees by salary department-wise.\n",
    "emps = W.partitionBy(\"Department\").orderBy(F.desc(\"Salary\"))\n",
    "df.withColumn(\"Rank\", F.rank().over(emps)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53563a01-9e81-4546-b8ec-042f2e723377",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+-----------------+\n|  Name| Department|Salary|Cumulative income|\n+------+-----------+------+-----------------+\n| Priya|Engineering| 60000|            60000|\n| Rahul|Engineering| 65000|           125000|\n|Naveen|Engineering| 70000|           195000|\n|Ananya|         HR| 52000|            52000|\n| Karan|         HR| 53000|           105000|\n|Fatima|  Marketing| 45000|            45000|\n|  Zoya|  Marketing| 48000|            93000|\n+------+-----------+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8. Calculate cumulative salary in each department.\n",
    "salry = W.partitionBy(\"Department\").orderBy(\"Salary\").rowsBetween(W.unboundedPreceding, W.currentRow)\n",
    "\n",
    "df.withColumn(\"Cumulative income\", F.sum(\"Salary\").over(salry)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8f57aa2-9019-4586-8d1a-6e847be6fa50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Date Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b769b9df-b19e-4700-b25b-8d3dacb418d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----------+\n|  Name| Department|Salary|  JoinDate|\n+------+-----------+------+----------+\n|Ananya|         HR| 52000|2022-12-14|\n| Rahul|Engineering| 65000|2020-04-26|\n| Priya|Engineering| 60000|2023-08-26|\n|  Zoya|  Marketing| 48000|2020-04-18|\n| Karan|         HR| 53000|2023-06-26|\n|Naveen|Engineering| 70000|2022-06-06|\n|Fatima|  Marketing| 45000|2020-10-02|\n+------+-----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Add a new column JoinDate with random dates between 2020 and 2023.\n",
    "df = df.withColumn(\"JoinDate\", F.date_add(\n",
    "    F.lit(\"2020-01-01\"),\n",
    "    F.floor(F.rand() * (365 * 4)).cast(\"int\")\n",
    "))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a895d92-1ad9-4818-b0fc-b084982d61d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+----------+---------------+\n|  Name| Department|Salary|  JoinDate|YearWithCompany|\n+------+-----------+------+----------+---------------+\n|Ananya|         HR| 52000|2022-12-14|            2.0|\n| Rahul|Engineering| 65000|2020-04-26|            5.0|\n| Priya|Engineering| 60000|2023-08-26|            2.0|\n|  Zoya|  Marketing| 48000|2020-04-18|            5.0|\n| Karan|         HR| 53000|2023-06-26|            2.0|\n|Naveen|Engineering| 70000|2022-06-06|            3.0|\n|Fatima|  Marketing| 45000|2020-10-02|            5.0|\n+------+-----------+------+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Add column YearsWithCompany using current_date() and datediff() .\n",
    "df.withColumn(\"YearWithCompany\", F.round((F.date_diff(F.current_date(), df.JoinDate) / 365))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e319738b-b61c-409d-ad3f-db3c70ca4834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#**Writing to Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7caa53c6-041a-43ea-9826-42e708b0655a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 11. Write the full employee DataFrame to CSV with headers.\n",
    "df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"employee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cd99dbd-fe91-46ad-aa8a-4da7864a4eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 12. Save the joined DataFrame to a Parquet file.\n",
    "df_joined.write.mode(\"overwrite\").parquet(\"df_joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "766f7bf7-68de-4c35-bb51-2b6483b6b74b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment-1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}